{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install --upgrade google-api-python-client --quiet\n",
    "!pip install nltk --quiet\n",
    "!pip install pandas --quiet\n",
    "!pip install nrclex --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\me\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# imports\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import googleapiclient\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nrclex import NRCLex\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from nltk.tokenize import casual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\junk\\ipykernel_12244\\1937675395.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  right_comment_df = pd.read_csv('Project_yt_comments.csv')\n"
     ]
    }
   ],
   "source": [
    "right_comment_df = pd.read_csv('Project_yt_comments.csv')\n",
    "right_title_df = pd.read_csv('Project_yt_titles.csv')\n",
    "demo_df = pd.read_csv('combine_democ_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textcleaner(row):\n",
    "    row = str(row)\n",
    "    row = row.lower()\n",
    "    # remove punctuation\n",
    "    row = re.sub(r'[^\\w\\s]', '', row)\n",
    "    #remove urls\n",
    "    row  = re.sub(r'http\\S+', '', row)\n",
    "    #remove mentions\n",
    "    row = re.sub(r\"(?<![@\\w])@(\\w{1,25})\", '', row)\n",
    "    #remove hashtags\n",
    "    row = re.sub(r\"(?<![#\\w])#(\\w{1,25})\", '',row)\n",
    "    #remove other special characters\n",
    "    row = re.sub('[^A-Za-z .-]+', '', row)\n",
    "        #remove digits\n",
    "    row = re.sub('\\d+', '', row)\n",
    "    row = row.strip(\" \")\n",
    "    row = re.sub('\\s+', ' ', row)\n",
    "    return row\n",
    "    \n",
    "stopeng = set(stopwords.words('english'))\n",
    "def remove_stop(text):\n",
    "    try:\n",
    "        words = text.split(' ')\n",
    "        valid = [x for x in words if x not in stopeng]\n",
    "        return(' '.join(valid))\n",
    "    except AttributeError:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN\n",
    "right_comment_df = right_comment_df.dropna()\n",
    "right_title_df = right_title_df.dropna()\n",
    "demo_df = demo_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from datetime to date\n",
    "right_comment_df['CommentCreationTime'] = right_comment_df['CommentCreationTime'].apply(lambda x: datetime.strptime(str(x)[0:10], '%Y-%m-%d').date())\n",
    "right_title_df['published_at'] = right_title_df['published_at'].apply(lambda x: datetime.strptime(str(x)[0:10], '%Y-%m-%d').date())\n",
    "demo_df['CommentCreationTime'] = demo_df['CommentCreationTime'].apply(lambda x: datetime.strptime(str(x)[0:10], '%Y-%m-%d').date())\n",
    "demo_df['published_at'] = demo_df['published_at'].apply(lambda x: datetime.strptime(str(x)[0:10], '%Y-%m-%d').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "right_comment_df['TweetToken'] = right_comment_df['CommentTitle'].apply(lambda x: casual.TweetTokenizer().tokenize(x))\n",
    "right_title_df['TweetToken'] = right_title_df['title'].apply(lambda x: casual.TweetTokenizer().tokenize(x))\n",
    "demo_df['TweetTokenTitle'] = demo_df['title'].apply(lambda x: casual.TweetTokenizer().tokenize(x))\n",
    "demo_df['TweetTokenComment'] = demo_df['CommentTitle'].apply(lambda x: casual.TweetTokenizer().tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "right_comment_df['CommentCleaned'] = right_comment_df['TweetToken'].apply(lambda x: remove_stop(textcleaner(x)))\n",
    "right_title_df['TitleCleaned'] = right_title_df['TweetToken'].apply(lambda x: remove_stop(textcleaner(x)))\n",
    "demo_df['TitleCleaned'] = demo_df['TweetTokenTitle'].apply(lambda x: remove_stop(textcleaner(x)))\n",
    "demo_df['CommentCleaned'] = demo_df['TweetTokenComment'].apply(lambda x: remove_stop(textcleaner(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrc_sen(text, cat):\n",
    "    sen = NRCLex(text)\n",
    "    if cat == 'pos':\n",
    "        return sen.affect_frequencies['positive']\n",
    "    else:\n",
    "        return sen.affect_frequencies['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_comment_df['PositiveScore'] = right_comment_df['CommentCleaned'].apply(lambda x: nrc_sen(x, 'pos'))\n",
    "right_comment_df['NegativeScore'] = right_comment_df['CommentCleaned'].apply(lambda x: nrc_sen(x, 'neg'))        \n",
    "right_title_df['PositiveScore'] = right_title_df['TitleCleaned'].apply(lambda x: nrc_sen(x, 'pos'))\n",
    "right_title_df['NegativeScore'] = right_title_df['TitleCleaned'].apply(lambda x: nrc_sen(x, 'neg'))        \n",
    "\n",
    "demo_df['PositiveScoreTitle'] = demo_df['TitleCleaned'].apply(lambda x: nrc_sen(x, 'pos'))\n",
    "demo_df['NegativeScoreTitle'] = demo_df['TitleCleaned'].apply(lambda x: nrc_sen(x, 'neg'))    \n",
    "demo_df['PositiveScoreComment'] = demo_df['CommentCleaned'].apply(lambda x: nrc_sen(x, 'pos'))    \n",
    "demo_df['NegativeScoreComment'] = demo_df['CommentCleaned'].apply(lambda x: nrc_sen(x, 'neg'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrc_emo(text, ver):\n",
    "    emo = NRCLex(text).affect_frequencies\n",
    "    max_emo = max(emo, key=emo.get)\n",
    "    max_score = emo[max_emo]\n",
    "    if ver == 'score':\n",
    "        return max_score\n",
    "    else:\n",
    "        return max_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_comment_df['Emotion'] = right_comment_df['CommentCleaned'].apply(lambda x: nrc_emo(x, 'emo'))\n",
    "right_comment_df['EmotionScore'] = right_comment_df['CommentCleaned'].apply(lambda x: nrc_emo(x, 'score'))        \n",
    "right_title_df['Emotion'] = right_title_df['TitleCleaned'].apply(lambda x: nrc_emo(x, 'emo'))\n",
    "right_title_df['EmotionScore'] = right_title_df['TitleCleaned'].apply(lambda x: nrc_emo(x, 'score'))        \n",
    "\n",
    "demo_df['EmotionTitle'] = demo_df['TitleCleaned'].apply(lambda x: nrc_emo(x, 'emo'))\n",
    "demo_df['EmotionScoreTitle'] = demo_df['TitleCleaned'].apply(lambda x: nrc_emo(x, 'score'))    \n",
    "demo_df['EmotionComment'] = demo_df['CommentCleaned'].apply(lambda x: nrc_emo(x, 'emo'))\n",
    "demo_df['EmotionScoreComment'] = demo_df['CommentCleaned'].apply(lambda x: nrc_emo(x, 'score'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "      <th>published_at</th>\n",
       "      <th>CommentId</th>\n",
       "      <th>CommentTitle</th>\n",
       "      <th>CommentCreationTime</th>\n",
       "      <th>CommentLikes</th>\n",
       "      <th>TweetTokenTitle</th>\n",
       "      <th>...</th>\n",
       "      <th>TitleCleaned</th>\n",
       "      <th>CommentCleaned</th>\n",
       "      <th>PositiveScoreTitle</th>\n",
       "      <th>NegativeScoreTitle</th>\n",
       "      <th>PositiveScoreComment</th>\n",
       "      <th>NegativeScoreComment</th>\n",
       "      <th>EmotionTitle</th>\n",
       "      <th>EmotionScoreTitle</th>\n",
       "      <th>EmotionComment</th>\n",
       "      <th>EmotionScoreComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vice</td>\n",
       "      <td>SwoRx3tstxY</td>\n",
       "      <td>We Uncovered an ISIS Mass Grave | Super Users</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>Ugws1dFQrp7AovnexrB4AaABAg</td>\n",
       "      <td>Bless the hard work of journalists! Seeing the...</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>146</td>\n",
       "      <td>[We, Uncovered, an, ISIS, Mass, Grave, |, Supe...</td>\n",
       "      <td>...</td>\n",
       "      <td>uncovered isis mass grave super users</td>\n",
       "      <td>bless hard work journalists seeing deplorable ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vice</td>\n",
       "      <td>SwoRx3tstxY</td>\n",
       "      <td>We Uncovered an ISIS Mass Grave | Super Users</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>UgxcNLZW2rAeMBklWD14AaABAg</td>\n",
       "      <td>Also I can't imagine  the amount mental trauma...</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>726</td>\n",
       "      <td>[We, Uncovered, an, ISIS, Mass, Grave, |, Supe...</td>\n",
       "      <td>...</td>\n",
       "      <td>uncovered isis mass grave super users</td>\n",
       "      <td>also cant imagine amount mental trauma work pu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vice</td>\n",
       "      <td>SwoRx3tstxY</td>\n",
       "      <td>We Uncovered an ISIS Mass Grave | Super Users</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>UgzFcqbEHILJ93hjvqh4AaABAg</td>\n",
       "      <td>This is so heartbreaking. What a horrific disp...</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>251</td>\n",
       "      <td>[We, Uncovered, an, ISIS, Mass, Grave, |, Supe...</td>\n",
       "      <td>...</td>\n",
       "      <td>uncovered isis mass grave super users</td>\n",
       "      <td>heartbreaking horrific display violence sorry ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vice</td>\n",
       "      <td>SwoRx3tstxY</td>\n",
       "      <td>We Uncovered an ISIS Mass Grave | Super Users</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>UgxYrGf2RJZeKbFEap14AaABAg</td>\n",
       "      <td>7:35 Social-media shouldn't be just summarily ...</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>219</td>\n",
       "      <td>[We, Uncovered, an, ISIS, Mass, Grave, |, Supe...</td>\n",
       "      <td>...</td>\n",
       "      <td>uncovered isis mass grave super users</td>\n",
       "      <td>socialmedia shouldnt summarily deleting flagge...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vice</td>\n",
       "      <td>SwoRx3tstxY</td>\n",
       "      <td>We Uncovered an ISIS Mass Grave | Super Users</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>Ugx5rmcME6ua2pMkojt4AaABAg</td>\n",
       "      <td>VICE NEVER Dissapoints! Amazing documentaries!...</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>127</td>\n",
       "      <td>[We, Uncovered, an, ISIS, Mass, Grave, |, Supe...</td>\n",
       "      <td>...</td>\n",
       "      <td>uncovered isis mass grave super users</td>\n",
       "      <td>vice never dissapoints amazing documentaries t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel     video_id                                          title keyword  \\\n",
       "0    Vice  SwoRx3tstxY  We Uncovered an ISIS Mass Grave | Super Users    ISIS   \n",
       "1    Vice  SwoRx3tstxY  We Uncovered an ISIS Mass Grave | Super Users    ISIS   \n",
       "2    Vice  SwoRx3tstxY  We Uncovered an ISIS Mass Grave | Super Users    ISIS   \n",
       "3    Vice  SwoRx3tstxY  We Uncovered an ISIS Mass Grave | Super Users    ISIS   \n",
       "4    Vice  SwoRx3tstxY  We Uncovered an ISIS Mass Grave | Super Users    ISIS   \n",
       "\n",
       "  published_at                   CommentId  \\\n",
       "0   2022-04-11  Ugws1dFQrp7AovnexrB4AaABAg   \n",
       "1   2022-04-11  UgxcNLZW2rAeMBklWD14AaABAg   \n",
       "2   2022-04-11  UgzFcqbEHILJ93hjvqh4AaABAg   \n",
       "3   2022-04-11  UgxYrGf2RJZeKbFEap14AaABAg   \n",
       "4   2022-04-11  Ugx5rmcME6ua2pMkojt4AaABAg   \n",
       "\n",
       "                                        CommentTitle CommentCreationTime  \\\n",
       "0  Bless the hard work of journalists! Seeing the...          2022-04-12   \n",
       "1  Also I can't imagine  the amount mental trauma...          2022-04-11   \n",
       "2  This is so heartbreaking. What a horrific disp...          2022-04-11   \n",
       "3  7:35 Social-media shouldn't be just summarily ...          2022-04-11   \n",
       "4  VICE NEVER Dissapoints! Amazing documentaries!...          2022-04-11   \n",
       "\n",
       "   CommentLikes                                    TweetTokenTitle  ...  \\\n",
       "0           146  [We, Uncovered, an, ISIS, Mass, Grave, |, Supe...  ...   \n",
       "1           726  [We, Uncovered, an, ISIS, Mass, Grave, |, Supe...  ...   \n",
       "2           251  [We, Uncovered, an, ISIS, Mass, Grave, |, Supe...  ...   \n",
       "3           219  [We, Uncovered, an, ISIS, Mass, Grave, |, Supe...  ...   \n",
       "4           127  [We, Uncovered, an, ISIS, Mass, Grave, |, Supe...  ...   \n",
       "\n",
       "                            TitleCleaned  \\\n",
       "0  uncovered isis mass grave super users   \n",
       "1  uncovered isis mass grave super users   \n",
       "2  uncovered isis mass grave super users   \n",
       "3  uncovered isis mass grave super users   \n",
       "4  uncovered isis mass grave super users   \n",
       "\n",
       "                                      CommentCleaned PositiveScoreTitle  \\\n",
       "0  bless hard work journalists seeing deplorable ...                0.0   \n",
       "1  also cant imagine amount mental trauma work pu...                0.0   \n",
       "2  heartbreaking horrific display violence sorry ...                0.0   \n",
       "3  socialmedia shouldnt summarily deleting flagge...                0.0   \n",
       "4  vice never dissapoints amazing documentaries t...                0.0   \n",
       "\n",
       "   NegativeScoreTitle  PositiveScoreComment  NegativeScoreComment  \\\n",
       "0            0.333333              0.066667              0.133333   \n",
       "1            0.333333              0.230769              0.076923   \n",
       "2            0.333333              0.000000              0.222222   \n",
       "3            0.333333              0.166667              0.166667   \n",
       "4            0.333333              0.285714              0.071429   \n",
       "\n",
       "   EmotionTitle EmotionScoreTitle  EmotionComment EmotionScoreComment  \n",
       "0          fear          0.333333            fear            0.200000  \n",
       "1          fear          0.333333        positive            0.230769  \n",
       "2          fear          0.333333            fear            0.222222  \n",
       "3          fear          0.333333            fear            0.166667  \n",
       "4          fear          0.333333        positive            0.285714  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
